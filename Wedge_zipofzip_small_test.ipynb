{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll work through some of the issues we will identify in class that we'll need to solve for the Wedge project. The key tasks are as follows:\n",
    "\n",
    "1. We need to get our file or files out of the zip file.\n",
    "1. We need to be able to read in the file. \n",
    "1. We need to do a few tests: looking for a header row, checking for delimiters, checking for quotes.\n",
    "1. We need to identify the owner number, which has index `45` in the row.\n",
    "1. We need to find the destination row.\n",
    "1. We need to write out the row. \n",
    "\n",
    "I've built some toy examples for us to play with in class. First, let's get a list of the files. The `os` package has a handy function `listdir` that will help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transArchive_201310_201312_small.zip',\n",
       " 'transArchive_201207_201209_small.zip',\n",
       " 'transArchive_201204_201206_inactive_small.zip',\n",
       " 'transArchive_201304_201306_inactive_small.zip',\n",
       " 'transArchive_201007_201009_small.zip',\n",
       " 'transArchive_201105_small.zip',\n",
       " 'transArchive_201110_201112_small.zip',\n",
       " 'transArchive_201304_201306_small.zip',\n",
       " 'transArchive_201404_201406_inactive_small.zip',\n",
       " 'transArchive_201504_201506_small.zip',\n",
       " '.DS_Store',\n",
       " 'transArchive_201612_small.zip',\n",
       " 'transArchive_201606_small.zip',\n",
       " 'transArchive_201401_201403_inactive_small.zip',\n",
       " 'transArchive_201407_201409_small.zip',\n",
       " 'transArchive_201201_201203_inactive_small.zip',\n",
       " 'transArchive_201301_201303_inactive_small.zip',\n",
       " 'transArchive_201310_201312_inactive_small.zip',\n",
       " 'transArchive_201107_201109_small.zip',\n",
       " 'transArchive_201601_small.zip',\n",
       " 'transArchive_201210_201212_inactive_small.zip',\n",
       " 'transArchive_201010_201012_small.zip',\n",
       " 'transArchive_201204_201206_small.zip',\n",
       " 'transArchive_201410_201412_inactive_small.zip',\n",
       " 'transArchive_201210_201212_small.zip',\n",
       " 'transArchive_201104_small.zip',\n",
       " 'transArchive_201307_201309_small.zip',\n",
       " 'transArchive_201512_small.zip',\n",
       " 'transArchive_201004_201006_small.zip',\n",
       " 'transArchive_201207_201209_inactive_small.zip',\n",
       " 'transArchive_201307_201309_inactive_small.zip',\n",
       " 'transArchive_201507_201509_small.zip',\n",
       " 'transArchive_201607_small.zip',\n",
       " 'transArchive_201410_201412_small.zip',\n",
       " 'transArchive_201404_201406_small.zip',\n",
       " 'transArchive_201407_201409_inactive_small.zip',\n",
       " 'transArchive_201602_small.zip',\n",
       " 'transArchive_201301_201303_small.zip',\n",
       " 'transArchive_201101_201103_small.zip',\n",
       " 'transArchive_201511_small.zip',\n",
       " 'transArchive_201610_small.zip',\n",
       " 'transArchive_201604_small.zip',\n",
       " 'transArchive_201501_201503_small.zip',\n",
       " 'transArchive_201609_small.zip',\n",
       " 'transArchive_201001_201003_small.zip',\n",
       " 'transArchive_201603_small.zip',\n",
       " 'transArchive_201106_small.zip',\n",
       " 'transArchive_201201_201203_small.zip',\n",
       " 'transArchive_201510_small.zip',\n",
       " 'transArchive_201605_small.zip',\n",
       " 'transArchive_201401_201403_small.zip',\n",
       " 'transArchive_201611_small.zip',\n",
       " 'transArchive_201608_small.zip',\n",
       " 'transArchive_201701_small.zip']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"wedge/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save these files to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_files = os.listdir(\"wedge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Zip Files\n",
    "\n",
    "Zip files are complicated, but useful. Here's a nice description I found on [GeeksForGeeks](https://www.geeksforgeeks.org/working-zip-files-python/):\n",
    "\n",
    "> ZIP is an archive file format that supports lossless data compression. By lossless compression, we mean that the compression algorithm allows the original data to be perfectly reconstructed from the compressed data. So, a ZIP file is a single file containing one or more compressed files, offering an ideal way to make large files smaller and keep related files together.\n",
    "\n",
    "So, one tricky thing is that a zip file is a _file_ but it can also contain lots of other sub-files, so it acts like a _folder_ as well.\n",
    "\n",
    "Q: Why don't we just unzip all the Wedge files and skip the unzipping? \n",
    "\n",
    "A: ?? \n",
    "\n",
    "There's a useful package for working with zip files called ... `zipfile`. Might be worth bookmarking the manual [page](https://docs.python.org/3/library/zipfile.html) for it. We won't need the whole package, so we'll just import the _Class_ `ZipFile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile # usually you'd do all these imports at the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name                                             Modified             Size\n",
      "transArchive_201310_201312_small.csv           2019-09-18 14:51:20      2949882\n",
      "Extracting all the files now...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Let's extract one file from the first zip in our list\n",
    "\n",
    "# opening the zip file in READ mode \n",
    "with ZipFile(\"wedge/\" + zip_files[0], 'r') as zf : \n",
    "    # printing what's in the zip file.  \n",
    "    zf.printdir() \n",
    "  \n",
    "    # extracting all the files \n",
    "    print('Extracting all the files now...') \n",
    "    zf.extractall() \n",
    "    print('Done!') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look in the folder for this repository and you'll see that the file was extracted into this directory. (Q: Why this one?) Now, we don't want to do this in practice, so we'll try to just read the files in the zip file. Let's delete the file that we just extracted just to be clean. The `os` package has a helpful function (`remove`) for us. But we need to get the name of the file first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transArchive_201310_201312_small.csv']\n"
     ]
    }
   ],
   "source": [
    "with ZipFile(\"wedge/\" + zip_files[0], 'r') as zf :\n",
    "    print(zf.namelist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: what is `namelist` returning?\n",
    "\n",
    "A: Name list out of 'transArchive_201310_201312_small.csv'. This is a list of one element, which is a string. The string is the name of the underlying csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's delete that spurious file we created\n",
    "with ZipFile(\"wedge/\" + zip_files[0], 'r') as zf :\n",
    "    this_file_list = zf.namelist()\n",
    "    os.remove(this_file_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make new directory as a test to hold files step 1 \n",
    "temp_folder_name = \"temp\"\n",
    "\n",
    "if not os.path.isdir(temp_folder_name): #if folder exisits\n",
    "    os.mkdir(temp_folder_name)          # if not, make it\n",
    "\n",
    "# extract all zipfile contents to directory\n",
    "for zip_file in zip_files: \n",
    "    with ZipFile(\"wedge/\" + zip_files[0], 'r') as zf :\n",
    "  \n",
    "            #extract all contents to temporary folder\n",
    "            zf.extractall(path=temp_folder_name)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete temporary directory as a test step 2\n",
    "\n",
    "#get files inside temp dir\n",
    "files_to_delete = os.listdir(temp_folder_name)\n",
    "\n",
    "#delete them one at a time\n",
    "for file in files_to_delete: \n",
    "    os.remove(temp_folder_name + \"/\" + file)\n",
    "    \n",
    "#remove the folder\n",
    "os.rmdir(temp_folder_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go check the folder for this repository on your machine and you'll see it's gone.\n",
    "\n",
    "In this next cell, write a loop over all the files in `zip_files` printing the contents to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transArchive_201310_201312_small.csv']\n",
      "['transArchive_201207_201209_small.csv']\n",
      "['transArchive_201204_201206_inactive_small.csv']\n",
      "['transArchive_201304_201306_inactive_small.csv']\n",
      "['transArchive_201007_201009_small.csv']\n",
      "['transArchive_201105_small.csv']\n",
      "['transArchive_201110_201112_small.csv']\n",
      "['transArchive_201304_201306_small.csv']\n",
      "['transArchive_201404_201406_inactive_small.csv']\n",
      "['transArchive_201504_201506_small.csv']\n",
      "['transArchive_201612_small.csv']\n",
      "['transArchive_201606_small.csv']\n",
      "['transArchive_201401_201403_inactive_small.csv']\n",
      "['transArchive_201407_201409_small.csv']\n",
      "['transArchive_201201_201203_inactive_small.csv']\n",
      "['transArchive_201301_201303_inactive_small.csv']\n",
      "['transArchive_201310_201312_inactive_small.csv']\n",
      "['transArchive_201107_201109_small.csv']\n",
      "['transArchive_201601_small.csv']\n",
      "['transArchive_201210_201212_inactive_small.csv']\n",
      "['transArchive_201010_201012_small.csv']\n",
      "['transArchive_201204_201206_small.csv']\n",
      "['transArchive_201410_201412_inactive_small.csv']\n",
      "['transArchive_201210_201212_small.csv']\n",
      "['transArchive_201104_small.csv']\n",
      "['transArchive_201307_201309_small.csv']\n",
      "['transArchive_201512_small.csv']\n",
      "['transArchive_201004_201006_small.csv']\n",
      "['transArchive_201207_201209_inactive_small.csv']\n",
      "['transArchive_201307_201309_inactive_small.csv']\n",
      "['transArchive_201507_201509_small.csv']\n",
      "['transArchive_201607_small.csv']\n",
      "['transArchive_201410_201412_small.csv']\n",
      "['transArchive_201404_201406_small.csv']\n",
      "['transArchive_201407_201409_inactive_small.csv']\n",
      "['transArchive_201602_small.csv']\n",
      "['transArchive_201301_201303_small.csv']\n",
      "['transArchive_201101_201103_small.csv']\n",
      "['transArchive_201511_small.csv']\n",
      "['transArchive_201610_small.csv']\n",
      "['transArchive_201604_small.csv']\n",
      "['transArchive_201501_201503_small.csv']\n",
      "['transArchive_201609_small.csv']\n",
      "['transArchive_201001_201003_small.csv']\n",
      "['transArchive_201603_small.csv']\n",
      "['transArchive_201106_small.csv']\n",
      "['transArchive_201201_201203_small.csv']\n",
      "['transArchive_201510_small.csv']\n",
      "['transArchive_201605_small.csv']\n",
      "['transArchive_201401_201403_small.csv']\n",
      "['transArchive_201611_small.csv']\n",
      "['transArchive_201608_small.csv']\n",
      "['transArchive_201701_small.csv']\n"
     ]
    }
   ],
   "source": [
    "for zipf in zip_files :\n",
    "    if zipf[-3:] == \"zip\":\n",
    "        with ZipFile(\"wedge/\" + zipf,'r') as zf :  \n",
    "            print(zf.namelist())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What do you notice about the contents of the zips? \n",
    "\n",
    "A: ?? \n",
    "\n",
    "Now, we're getting close. At this point, we'd like to do something like the following:\n",
    "\n",
    "1. Open a zip file\n",
    "1. Get a list of the files in there\n",
    "1. Read those files as we've read plain text files before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\"datetime\",\"register_no\",\"emp_no\",\"trans_no\",\"upc\",\"description\",\"trans_type\",\"trans_subtype\",\"trans_status\",\"department\",\"quantity\",\"Scale\",\"cost\",\"unitPrice\",\"total\",\"regPrice\",\"altPrice\",\"tax\",\"taxexempt\",\"foodstamp\",\"wicable\",\"discount\",\"memDiscount\",\"discountable\",\"discounttype\",\"voided\",\"percentDiscount\",\"ItemQtty\",\"volDiscType\",\"volume\",\"VolSpecial\",\"mixMatch\",\"matched\",\"memType\",\"staff\",\"numflag\",\"itemstatus\",\"tenderstatus\",\"charflag\",\"varflag\",\"batchHeaderID\",\"local\",\"organic\",\"display\",\"receipt\",\"card_no\",\"store\",\"branch\",\"match_id\",\"trans_id\"\\r\\n'\n",
      "b'\"2013-10-01 07:11:53\",\"700\",\"700\",\"829\",\"0000000009118\",\"KB:Tofu Creole/Br.Rice/Adult\",\"I\",\" \",\" \",\"8\",\"1\",\"0\",\"0.0000\",\"10.0000\",\"10.0000\",\"10.0000\",\"0.0000\",\"1\",\"0\",\"0\",\"0\",\"0.0000\",\"0.0000\",\"0\",\"0\",\"0\",\"0.00000000\",\"1\",\"0\",\"1\",\"0.0000\",\"0\",\"0\",\" \",\"0\",\"1\",\"0\",\"0\",,\"0\",NULL,\"1\",\"0\",\" \",\"0\",\"3\",\"512\",\"0\",\"0\",\"1\"\\r\\n'\n",
      "b'\"2013-10-01 07:11:53\",\"700\",\"700\",\"829\",\"0000000009120\",\"KB:Beef Stroganoff/Adult\",\"I\",\" \",\" \",\"8\",\"1\",\"0\",\"0.0000\",\"10.0000\",\"10.0000\",\"10.0000\",\"0.0000\",\"1\",\"0\",\"0\",\"0\",\"0.0000\",\"0.0000\",\"0\",\"0\",\"0\",\"0.00000000\",\"1\",\"0\",\"1\",\"0.0000\",\"0\",\"0\",\" \",\"0\",\"1\",\"0\",\"0\",,\"0\",NULL,\"1\",\"0\",\" \",\"0\",\"3\",\"512\",\"0\",\"0\",\"2\"\\r\\n'\n",
      "b'\"2013-10-01 07:11:53\",\"700\",\"700\",\"829\",\"0000000009122\",\"KB:Chkn.Noodle Soup/Child\",\"I\",\" \",\" \",\"8\",\"1\",\"0\",\"0.0000\",\"5.0000\",\"5.0000\",\"5.0000\",\"0.0000\",\"1\",\"0\",\"0\",\"0\",\"0.0000\",\"0.0000\",\"0\",\"0\",\"0\",\"0.00000000\",\"1\",\"0\",\"1\",\"0.0000\",\"0\",\"0\",\" \",\"0\",\"1\",\"0\",\"0\",,\"0\",NULL,\"1\",\"0\",\" \",\"0\",\"3\",\"512\",\"0\",\"0\",\"3\"\\r\\n'\n",
      "b'\"2013-10-01 07:11:53\",\"700\",\"700\",\"829\",\"0000000009123\",\"KB:Honey Carrot Cake/Adult\",\"I\",\" \",\" \",\"8\",\"2\",\"0\",\"0.0000\",\"2.2500\",\"4.5000\",\"2.2500\",\"0.0000\",\"1\",\"0\",\"0\",\"0\",\"0.0000\",\"0.0000\",\"0\",\"0\",\"0\",\"0.00000000\",\"2\",\"0\",\"2\",\"0.0000\",\"0\",\"0\",\" \",\"0\",\"1\",\"0\",\"0\",,\"0\",NULL,\"1\",\"0\",\" \",\"0\",\"3\",\"512\",\"0\",\"0\",\"4\"\\r\\n'\n",
      "b'\"2013-10-01 07:11:53\",\"700\",\"700\",\"829\",\"0020398500000\",\"Catering Delivery Fee\",\"I\",\" \",\" \",\"8\",\"0\",\"0\",\"0.0000\",\"0.0100\",\"0.0000\",\"0.0100\",\"0.0000\",\"1\",\"0\",\"0\",\"0\",\"0.0000\",\"0.0000\",\"0\",\"0\",\"0\",\"0.00000000\",\"1\",\"0\",\"0\",\"0.0000\",\"0\",\"0\",\" \",\"0\",\"1\",\"0\",\"0\",,\"0\",NULL,\"1\",\"0\",\" \",\"0\",\"3\",\"512\",\"0\",\"0\",\"6\"\\r\\n'\n"
     ]
    }
   ],
   "source": [
    "this_zf = zip_files[0]\n",
    "\n",
    "with ZipFile(\"wedge/\" + this_zf,'r') as zf :\n",
    "    zipped_files = zf.namelist()\n",
    "    \n",
    "    for file_name in zipped_files :\n",
    "        with zf.open(file_name,'r') as input_file :\n",
    "            for idx, line in enumerate(input_file) :\n",
    "                print(line)\n",
    "                if idx >= 5 :\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's spend a little time reading what's going on here. \n",
    "\n",
    "Q: What's up with the `b'some string stuff'`? \n",
    "\n",
    "A: ?? \n",
    "\n",
    "\n",
    "Do deal with byte strings, we can use `io.TextIOWrapper` to get the job done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"datetime\",\"register_no\",\"emp_no\",\"trans_no\",\"upc\",\"description\",\"trans_type\",\"trans_subtype\",\"trans_status\",\"department\",\"quantity\",\"Scale\",\"cost\",\"unitPrice\",\"total\",\"regPrice\",\"altPrice\",\"tax\",\"taxexempt\",\"foodstamp\",\"wicable\",\"discount\",\"memDiscount\",\"discountable\",\"discounttype\",\"voided\",\"percentDiscount\",\"ItemQtty\",\"volDiscType\",\"volume\",\"VolSpecial\",\"mixMatch\",\"matched\",\"memType\",\"staff\",\"numflag\",\"itemstatus\",\"tenderstatus\",\"charflag\",\"varflag\",\"batchHeaderID\",\"local\",\"organic\",\"display\",\"receipt\",\"card_no\",\"store\",\"branch\",\"match_id\",\"trans_id\"\n",
      "\n",
      "\"2013-10-01 07:11:53\",\"700\",\"700\",\"829\",\"0000000009118\",\"KB:Tofu Creole/Br.Rice/Adult\",\"I\",\" \",\" \",\"8\",\"1\",\"0\",\"0.0000\",\"10.0000\",\"10.0000\",\"10.0000\",\"0.0000\",\"1\",\"0\",\"0\",\"0\",\"0.0000\",\"0.0000\",\"0\",\"0\",\"0\",\"0.00000000\",\"1\",\"0\",\"1\",\"0.0000\",\"0\",\"0\",\" \",\"0\",\"1\",\"0\",\"0\",,\"0\",NULL,\"1\",\"0\",\" \",\"0\",\"3\",\"512\",\"0\",\"0\",\"1\"\n",
      "\n",
      "\"2013-10-01 07:11:53\",\"700\",\"700\",\"829\",\"0000000009120\",\"KB:Beef Stroganoff/Adult\",\"I\",\" \",\" \",\"8\",\"1\",\"0\",\"0.0000\",\"10.0000\",\"10.0000\",\"10.0000\",\"0.0000\",\"1\",\"0\",\"0\",\"0\",\"0.0000\",\"0.0000\",\"0\",\"0\",\"0\",\"0.00000000\",\"1\",\"0\",\"1\",\"0.0000\",\"0\",\"0\",\" \",\"0\",\"1\",\"0\",\"0\",,\"0\",NULL,\"1\",\"0\",\" \",\"0\",\"3\",\"512\",\"0\",\"0\",\"2\"\n",
      "\n",
      "\"2013-10-01 07:11:53\",\"700\",\"700\",\"829\",\"0000000009122\",\"KB:Chkn.Noodle Soup/Child\",\"I\",\" \",\" \",\"8\",\"1\",\"0\",\"0.0000\",\"5.0000\",\"5.0000\",\"5.0000\",\"0.0000\",\"1\",\"0\",\"0\",\"0\",\"0.0000\",\"0.0000\",\"0\",\"0\",\"0\",\"0.00000000\",\"1\",\"0\",\"1\",\"0.0000\",\"0\",\"0\",\" \",\"0\",\"1\",\"0\",\"0\",,\"0\",NULL,\"1\",\"0\",\" \",\"0\",\"3\",\"512\",\"0\",\"0\",\"3\"\n",
      "\n",
      "\"2013-10-01 07:11:53\",\"700\",\"700\",\"829\",\"0000000009123\",\"KB:Honey Carrot Cake/Adult\",\"I\",\" \",\" \",\"8\",\"2\",\"0\",\"0.0000\",\"2.2500\",\"4.5000\",\"2.2500\",\"0.0000\",\"1\",\"0\",\"0\",\"0\",\"0.0000\",\"0.0000\",\"0\",\"0\",\"0\",\"0.00000000\",\"2\",\"0\",\"2\",\"0.0000\",\"0\",\"0\",\" \",\"0\",\"1\",\"0\",\"0\",,\"0\",NULL,\"1\",\"0\",\" \",\"0\",\"3\",\"512\",\"0\",\"0\",\"4\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "this_zf = zip_files[0]\n",
    "\n",
    "with ZipFile(\"wedge/\" + this_zf,'r') as zf :\n",
    "    zipped_files = zf.namelist()\n",
    "    \n",
    "    for file_name in zipped_files :\n",
    "        input_file = zf.open(file_name,'r')\n",
    "        input_file = io.TextIOWrapper(input_file,encoding=\"utf-8\")\n",
    "        \n",
    "        for idx, line in enumerate(input_file) :\n",
    "            print(line)\n",
    "            if idx > 3 :\n",
    "                break\n",
    "\n",
    "        input_file.close() # tidy up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What do you notice about this output? \n",
    "\n",
    "A: ??\n",
    "\n",
    "Okay, now we're close to finishing our work with zip files. In the cell below, write code that will \n",
    "\n",
    "1. Iterate over every zip file.\n",
    "1. Print out the name of the containing file. \n",
    "1. Print out the first 3 lines of each file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transArchive_201310_201312_small.csv\n",
      "['\"datetime\",\"register_no\",\"emp_no\",\"trans_no\",\"upc\",\"description\",\"trans_type\",\"trans_subtype\",\"trans_status\",\"department\",\"quantity\",\"Scale\",\"cost\",\"unitPrice\",\"total\",\"regPrice\",\"altPrice\",\"tax\",\"taxexempt\",\"foodstamp\",\"wicable\",\"discount\",\"memDiscount\",\"discountable\",\"discounttype\",\"voided\",\"percentDiscount\",\"ItemQtty\",\"volDiscType\",\"volume\",\"VolSpecial\",\"mixMatch\",\"matched\",\"memType\",\"staff\",\"numflag\",\"itemstatus\",\"tenderstatus\",\"charflag\",\"varflag\",\"batchHeaderID\",\"local\",\"organic\",\"display\",\"receipt\",\"card_no\",\"store\",\"branch\",\"match_id\",\"trans_id\"']\n",
      "['\"2013-10-01 07:11:53\",\"700\",\"700\",\"829\",\"0000000009118\",\"KB:Tofu Creole/Br.Rice/Adult\",\"I\",\" \",\" \",\"8\",\"1\",\"0\",\"0.0000\",\"10.0000\",\"10.0000\",\"10.0000\",\"0.0000\",\"1\",\"0\",\"0\",\"0\",\"0.0000\",\"0.0000\",\"0\",\"0\",\"0\",\"0.00000000\",\"1\",\"0\",\"1\",\"0.0000\",\"0\",\"0\",\" \",\"0\",\"1\",\"0\",\"0\",,\"0\",NULL,\"1\",\"0\",\" \",\"0\",\"3\",\"512\",\"0\",\"0\",\"1\"']\n",
      "['\"2013-10-01 07:11:53\",\"700\",\"700\",\"829\",\"0000000009120\",\"KB:Beef Stroganoff/Adult\",\"I\",\" \",\" \",\"8\",\"1\",\"0\",\"0.0000\",\"10.0000\",\"10.0000\",\"10.0000\",\"0.0000\",\"1\",\"0\",\"0\",\"0\",\"0.0000\",\"0.0000\",\"0\",\"0\",\"0\",\"0.00000000\",\"1\",\"0\",\"1\",\"0.0000\",\"0\",\"0\",\" \",\"0\",\"1\",\"0\",\"0\",,\"0\",NULL,\"1\",\"0\",\" \",\"0\",\"3\",\"512\",\"0\",\"0\",\"2\"']\n",
      "transArchive_201207_201209_small.csv\n",
      "['\"datetime\",\"register_no\",\"emp_no\",\"trans_no\",\"upc\",\"description\",\"trans_type\",\"trans_subtype\",\"trans_status\",\"department\",\"quantity\",\"Scale\",\"cost\",\"unitPrice\",\"total\",\"regPrice\",\"altPrice\",\"tax\",\"taxexempt\",\"foodstamp\",\"wicable\",\"discount\",\"memDiscount\",\"discountable\",\"discounttype\",\"voided\",\"percentDiscount\",\"ItemQtty\",\"volDiscType\",\"volume\",\"VolSpecial\",\"mixMatch\",\"matched\",\"memType\",\"staff\",\"numflag\",\"itemstatus\",\"tenderstatus\",\"charflag\",\"varflag\",\"batchHeaderID\",\"local\",\"organic\",\"display\",\"receipt\",\"card_no\",\"store\",\"branch\",\"match_id\",\"trans_id\"']\n",
      "['\"2012-07-01 08:20:15\",\"16\",\"54\",\"1\",\"0000000009506\",\"Offsite: Plain Croissant\",\"I\",\" \",\" \",\"17\",\"7\",\"0\",\"0.2100\",\"1.3900\",\"9.7300\",\"1.3900\",\"0.0000\",\"0\",\"0\",\"1\",\"0\",\"0.0000\",\"0.0000\",\"1\",\"0\",\"0\",NULL,\"7\",\"0\",\"0\",\"0.0000\",\"0\",\"0\",,NULL,\"1\",\"0\",\"0\",,\"0\",NULL,\"0\",\"0\",\" \",\"0\",\"50054\",\"16\",\"0\",\"0\",\"4\"']\n",
      "['\"2012-07-01 08:20:17\",\"16\",\"54\",\"1\",\"0000000009505\",\"Offsite: Chocolate Croissant\",\"I\",\" \",\" \",\"17\",\"4\",\"0\",\"0.3500\",\"1.5900\",\"6.3600\",\"1.5900\",\"0.0000\",\"0\",\"0\",\"1\",\"0\",\"0.0000\",\"0.0000\",\"1\",\"0\",\"0\",NULL,\"4\",\"0\",\"0\",\"0.0000\",\"0\",\"0\",,NULL,\"1\",\"0\",\"0\",,\"0\",NULL,\"0\",\"0\",\" \",\"0\",\"50054\",\"16\",\"0\",\"0\",\"5\"']\n",
      "transArchive_201204_201206_inactive_small.csv\n",
      "['\"datetime\";\"register_no\";\"emp_no\";\"trans_no\";\"upc\";\"description\";\"trans_type\";\"trans_subtype\";\"trans_status\";\"department\";\"quantity\";\"Scale\";\"cost\";\"unitPrice\";\"total\";\"regPrice\";\"altPrice\";\"tax\";\"taxexempt\";\"foodstamp\";\"wicable\";\"discount\";\"memDiscount\";\"discountable\";\"discounttype\";\"voided\";\"percentDiscount\";\"ItemQtty\";\"volDiscType\";\"volume\";\"VolSpecial\";\"mixMatch\";\"matched\";\"memType\";\"staff\";\"numflag\";\"itemstatus\";\"tenderstatus\";\"charflag\";\"varflag\";\"batchHeaderID\";\"local\";\"organic\";\"display\";\"receipt\";\"card_no\";\"store\";\"branch\";\"match_id\";\"trans_id\"']\n",
      "['\"2012-04-01 09:18:09\";\"5\";\"34\";\"8\";\"0007234000126\";\"1% Milk SR 64oz Sch\";\"I\";\" \";\" \";\"4\";\"1\";\"0\";\"1.6800\";\"2.0900\";\"2.0900\";\"2.0900\";\"0.0000\";\"0\";\"0\";\"1\";\"0\";\"0.0000\";\"0.0000\";\"1\";\"0\";\"0\";\"10.00000000\";\"1\";\"0\";\"0\";\"0.0000\";\"0\";\"0\";;NULL;\"1\";\"0\";\"0\";;\"0\";NULL;\"0\";\"0\";\" \";\"0\";\"44966\";\"1\";\"0\";\"0\";\"1\"']\n",
      "['\"2012-04-01 09:18:12\";\"5\";\"34\";\"8\";\"0005342300076\";\"O.Fat Flush Tortillas 8oz FM\";\"I\";\" \";\" \";\"4\";\"1\";\"0\";\"2.1600\";\"3.9900\";\"3.9900\";\"3.9900\";\"0.0000\";\"0\";\"0\";\"1\";\"0\";\"0.0000\";\"0.0000\";\"1\";\"0\";\"0\";\"10.00000000\";\"1\";\"0\";\"0\";\"0.0000\";\"0\";\"0\";;NULL;\"1\";\"0\";\"0\";;\"0\";NULL;\"0\";\"1\";\" \";\"0\";\"44966\";\"1\";\"0\";\"0\";\"2\"']\n",
      "transArchive_201304_201306_inactive_small.csv\n",
      "['\"datetime\";\"register_no\";\"emp_no\";\"trans_no\";\"upc\";\"description\";\"trans_type\";\"trans_subtype\";\"trans_status\";\"department\";\"quantity\";\"Scale\";\"cost\";\"unitPrice\";\"total\";\"regPrice\";\"altPrice\";\"tax\";\"taxexempt\";\"foodstamp\";\"wicable\";\"discount\";\"memDiscount\";\"discountable\";\"discounttype\";\"voided\";\"percentDiscount\";\"ItemQtty\";\"volDiscType\";\"volume\";\"VolSpecial\";\"mixMatch\";\"matched\";\"memType\";\"staff\";\"numflag\";\"itemstatus\";\"tenderstatus\";\"charflag\";\"varflag\";\"batchHeaderID\";\"local\";\"organic\";\"display\";\"receipt\";\"card_no\";\"store\";\"branch\";\"match_id\";\"trans_id\"']\n",
      "['\"2013-04-01 09:28:38\";\"2\";\"44\";\"2\";\"0076333201701\";\"Sport-Top Steel Bottle 12oz KK\";\"I\";\" \";\" \";\"9\";\"1\";\"0\";\"8.5000\";\"15.4900\";\"15.4900\";\"15.4900\";\"0.0000\";\"1\";\"0\";\"0\";\"0\";\"0.0000\";\"0.0000\";\"1\";\"0\";\"0\";\"10.00000000\";\"1\";\"0\";\"0\";\"0.0000\";\"0\";\"0\";;NULL;\"0\";\"0\";\"0\";;\"0\";NULL;\"0\";\"0\";\" \";\"0\";\"47885\";\"1\";\"0\";\"0\";\"1\"']\n",
      "['\"2013-04-01 09:28:42\";\"2\";\"44\";\"2\";\"0089348100141\";\"Hand Sanitizer Wipes 10ct CW\";\"I\";\" \";\" \";\"11\";\"1\";\"0\";\"1.8140\";\"3.5900\";\"3.5900\";\"3.5900\";\"0.0000\";\"0\";\"0\";\"0\";\"0\";\"0.0000\";\"0.0000\";\"1\";\"0\";\"0\";\"10.00000000\";\"1\";\"0\";\"0\";\"0.0000\";\"0\";\"0\";;NULL;\"0\";\"0\";\"0\";;\"0\";NULL;\"0\";\"0\";\" \";\"0\";\"47885\";\"1\";\"0\";\"0\";\"3\"']\n",
      "transArchive_201007_201009_small.csv\n",
      "['\"datetime\",\"register_no\",\"emp_no\",\"trans_no\",\"upc\",\"description\",\"trans_type\",\"trans_subtype\",\"trans_status\",\"department\",\"quantity\",\"Scale\",\"cost\",\"unitPrice\",\"total\",\"regPrice\",\"altPrice\",\"tax\",\"taxexempt\",\"foodstamp\",\"wicable\",\"discount\",\"memDiscount\",\"discountable\",\"discounttype\",\"voided\",\"percentDiscount\",\"ItemQtty\",\"volDiscType\",\"volume\",\"VolSpecial\",\"mixMatch\",\"matched\",\"memType\",\"staff\",\"numflag\",\"itemstatus\",\"tenderstatus\",\"charflag\",\"varflag\",\"batchHeaderID\",\"local\",\"organic\",\"display\",\"receipt\",\"card_no\",\"store\",\"branch\",\"match_id\",\"trans_id\"']\n",
      "['\"2010-07-01 08:57:37\",\"8\",\"3\",\"1\",\"0000000000049\",\"WEDGE MUFFIN\",\"I\",\" \",\" \",\"8\",\"1\",\"0\",\"0.4503\",\"2.2900\",\"2.2900\",\"2.2900\",\"0.0000\",\"0\",\"0\",\"1\",\"0\",\"0.0000\",\"0.0000\",\"1\",\"0\",\"0\",\"0.00000000\",\"1\",\"0\",\"0\",\"0.0000\",\"0\",\"0\",,\"0\",\"5\",\"0\",\"0\",,\"0\",NULL,\"0\",NULL,,\"0\",\"12539\",\"1\",\"0\",\"0\",\"1\"']\n",
      "['\"2010-07-01 08:57:37\",\"8\",\"3\",\"1\",\"0000000000049\",\"WEDGE MUFFIN\",\"I\",\" \",\" \",\"8\",\"1\",\"0\",\"0.4503\",\"2.2900\",\"2.2900\",\"2.2900\",\"0.0000\",\"0\",\"0\",\"1\",\"0\",\"0.0000\",\"0.0000\",\"1\",\"0\",\"0\",\"0.00000000\",\"1\",\"0\",\"0\",\"0.0000\",\"0\",\"0\",,\"0\",\"5\",\"0\",\"0\",,\"0\",NULL,\"0\",NULL,,\"0\",\"12539\",\"1\",\"0\",\"0\",\"2\"']\n",
      "transArchive_201105_small.csv\n",
      "['datetime,register_no,emp_no,trans_no,upc,description,trans_type,trans_subtype,trans_status,department,quantity,Scale,cost,unitPrice,total,regPrice,altPrice,tax,taxexempt,foodstamp,wicable,discount,memDiscount,discountable,discounttype,voided,percentDiscount,ItemQtty,volDiscType,volume,VolSpecial,mixMatch,matched,memType,staff,numflag,itemstatus,tenderstatus,charflag,varflag,batchHeaderID,local,organic,display,receipt,card_no,store,branch,match_id,trans_id']\n",
      "['\"2011-05-01 08:59:40\",5,36,2,0071833422113,\"Tea Tree Mouthwash 16oz DE\",I,\" \",\" \",11,1,0,3.8700,7.6900,7.6900,7.6900,0.0000,1,0,0,0,0.0000,0.0000,1,0,0,0.00000000,1,0,0,0.0000,0,0,,NULL,0,0,0,,0,NULL,0,0,\" \",0,3,1,0,0,1']\n",
      "['\"2011-05-01 08:59:43\",5,36,2,0071833422113,\"Tea Tree Mouthwash 16oz DE\",I,\" \",\" \",11,1,0,3.8700,7.6900,7.6900,7.6900,0.0000,1,0,0,0,0.0000,0.0000,1,0,0,0.00000000,1,0,0,0.0000,0,0,,NULL,0,0,0,,0,NULL,0,0,\" \",0,3,1,0,0,2']\n",
      "transArchive_201110_201112_small.csv\n",
      "['\"datetime\",\"register_no\",\"emp_no\",\"trans_no\",\"upc\",\"description\",\"trans_type\",\"trans_subtype\",\"trans_status\",\"department\",\"quantity\",\"Scale\",\"cost\",\"unitPrice\",\"total\",\"regPrice\",\"altPrice\",\"tax\",\"taxexempt\",\"foodstamp\",\"wicable\",\"discount\",\"memDiscount\",\"discountable\",\"discounttype\",\"voided\",\"percentDiscount\",\"ItemQtty\",\"volDiscType\",\"volume\",\"VolSpecial\",\"mixMatch\",\"matched\",\"memType\",\"staff\",\"numflag\",\"itemstatus\",\"tenderstatus\",\"charflag\",\"varflag\",\"batchHeaderID\",\"local\",\"organic\",\"display\",\"receipt\",\"card_no\",\"store\",\"branch\",\"match_id\",\"trans_id\"']\n",
      "['\"2011-10-01 08:57:23\",\"16\",\"54\",\"6\",\"0000000040423\",\"CC Chai 12oz\",\"I\",\" \",\" \",\"14\",\"1\",\"0\",\"0.6407\",\"2.9900\",\"2.9900\",\"2.9900\",\"0.0000\",\"1\",\"0\",\"0\",\"0\",\"0.0000\",\"0.0000\",\"1\",\"0\",\"0\",\"0.00000000\",\"1\",\"0\",\"0\",\"0.0000\",\"0\",\"0\",,NULL,\"5\",\"0\",\"0\",,\"0\",NULL,\"0\",\"0\",\" \",\"0\",\"13381\",\"1\",\"0\",\"0\",\"1\"']\n",
      "['\"2011-10-01 08:57:42\",\"16\",\"54\",\"6\",\"0\",\"Cash\",\"T\",\"CA\",\" \",\"0\",\"0\",\"0\",\"0.0000\",\"0.0000\",\"-5.0000\",\"0.0000\",\"0.0000\",\"0\",\"0\",\"0\",\"0\",\"0.0000\",\"0.0000\",\"0\",\"0\",\"0\",NULL,\"0\",\"0\",\"0\",\"0.0000\",\"0\",\"0\",,NULL,\"0\",\"0\",\"0\",,\"0\",NULL,\"0\",NULL,\" \",\"0\",\"13381\",\"1\",\"0\",\"0\",\"5\"']\n",
      "transArchive_201304_201306_small.csv\n",
      "['\"datetime\",\"register_no\",\"emp_no\",\"trans_no\",\"upc\",\"description\",\"trans_type\",\"trans_subtype\",\"trans_status\",\"department\",\"quantity\",\"Scale\",\"cost\",\"unitPrice\",\"total\",\"regPrice\",\"altPrice\",\"tax\",\"taxexempt\",\"foodstamp\",\"wicable\",\"discount\",\"memDiscount\",\"discountable\",\"discounttype\",\"voided\",\"percentDiscount\",\"ItemQtty\",\"volDiscType\",\"volume\",\"VolSpecial\",\"mixMatch\",\"matched\",\"memType\",\"staff\",\"numflag\",\"itemstatus\",\"tenderstatus\",\"charflag\",\"varflag\",\"batchHeaderID\",\"local\",\"organic\",\"display\",\"receipt\",\"card_no\",\"store\",\"branch\",\"match_id\",\"trans_id\"']\n",
      "['\"2013-04-01 07:11:41\",\"16\",\"54\",\"1\",\"0000000009506\",\"Offsite: Plain Croissant\",\"I\",\" \",\" \",\"17\",\"5\",\"0\",\"0.2100\",\"1.3900\",\"6.9500\",\"1.3900\",\"0.0000\",\"0\",\"0\",\"1\",\"0\",\"0.0000\",\"0.0000\",\"1\",\"0\",\"0\",\"0.00000000\",\"5\",\"0\",\"0\",\"0.0000\",\"0\",\"0\",,NULL,\"1\",\"0\",\"0\",,\"0\",NULL,\"0\",\"0\",\" \",\"0\",\"50052\",\"8\",\"0\",\"0\",\"1\"']\n",
      "['\"2013-04-01 07:11:52\",\"16\",\"54\",\"1\",\"0000000009505\",\"Offsite: Chocolate Croissant\",\"I\",\" \",\" \",\"17\",\"5\",\"0\",\"0.3500\",\"1.5900\",\"7.9500\",\"1.5900\",\"0.0000\",\"0\",\"0\",\"1\",\"0\",\"0.0000\",\"0.0000\",\"1\",\"0\",\"0\",NULL,\"5\",\"0\",\"0\",\"0.0000\",\"0\",\"0\",,NULL,\"1\",\"0\",\"0\",,\"0\",NULL,\"0\",\"0\",\" \",\"0\",\"50052\",\"8\",\"0\",\"0\",\"5\"']\n",
      "transArchive_201404_201406_inactive_small.csv\n",
      "['\"datetime\";\"register_no\";\"emp_no\";\"trans_no\";\"upc\";\"description\";\"trans_type\";\"trans_subtype\";\"trans_status\";\"department\";\"quantity\";\"Scale\";\"cost\";\"unitPrice\";\"total\";\"regPrice\";\"altPrice\";\"tax\";\"taxexempt\";\"foodstamp\";\"wicable\";\"discount\";\"memDiscount\";\"discountable\";\"discounttype\";\"voided\";\"percentDiscount\";\"ItemQtty\";\"volDiscType\";\"volume\";\"VolSpecial\";\"mixMatch\";\"matched\";\"memType\";\"staff\";\"numflag\";\"itemstatus\";\"tenderstatus\";\"charflag\";\"varflag\";\"batchHeaderID\";\"local\";\"organic\";\"display\";\"receipt\";\"card_no\";\"store\";\"branch\";\"match_id\";\"trans_id\"']\n",
      "['\"2014-04-01 09:24:33\";\"7\";\"71\";\"31\";\"0000000000049\";\"Wedge Muffin\";\"I\";\" \";\" \";\"8\";\"2\";\"0\";\"0.5294\";\"2.3900\";\"4.7800\";\"2.3900\";\"0.0000\";\"0\";\"0\";\"1\";\"0\";\"0.0000\";\"0.0000\";\"1\";\"0\";\"0\";\"0.00000000\";\"2\";\"0\";\"0\";\"0.0000\";\"0\";\"0\";NULL;NULL;\"5\";\"0\";\"0\";;\"0\";NULL;\"0\";\"0\";;\"0\";\"48318\";\"1\";\"0\";\"0\";\"1\"']\n",
      "['\"2014-04-01 09:24:34\";\"7\";\"71\";\"31\";\"0000000000039\";\"Wedge Scone\";\"I\";\" \";\" \";\"8\";\"2\";\"0\";\"0.5785\";\"2.3900\";\"4.7800\";\"2.3900\";\"0.0000\";\"0\";\"0\";\"1\";\"0\";\"0.0000\";\"0.0000\";\"1\";\"0\";\"0\";\"0.00000000\";\"2\";\"0\";\"0\";\"0.0000\";\"0\";\"0\";NULL;NULL;\"5\";\"0\";\"0\";;\"0\";NULL;\"0\";\"0\";;\"0\";\"48318\";\"1\";\"0\";\"0\";\"2\"']\n",
      "transArchive_201504_201506_small.csv\n",
      "['\"datetime\",\"register_no\",\"emp_no\",\"trans_no\",\"upc\",\"description\",\"trans_type\",\"trans_subtype\",\"trans_status\",\"department\",\"quantity\",\"Scale\",\"cost\",\"unitPrice\",\"total\",\"regPrice\",\"altPrice\",\"tax\",\"taxexempt\",\"foodstamp\",\"wicable\",\"discount\",\"memDiscount\",\"discountable\",\"discounttype\",\"voided\",\"percentDiscount\",\"ItemQtty\",\"volDiscType\",\"volume\",\"VolSpecial\",\"mixMatch\",\"matched\",\"memType\",\"staff\",\"numflag\",\"itemstatus\",\"tenderstatus\",\"charflag\",\"varflag\",\"batchHeaderID\",\"local\",\"organic\",\"display\",\"receipt\",\"card_no\",\"store\",\"branch\",\"match_id\",\"trans_id\"']\n",
      "['\"2015-04-01 07:10:51\",\"51\",\"94\",\"4\",\"0000000004345\",\"BURRITOS Breakfast\",\"I\",\" \",\" \",\"8\",\"1\",\"0\",\"0.0000\",\"6.0000\",\"6.0000\",\"6.0000\",NULL,\"1\",\"0\",\"0\",NULL,\"0.0000\",\"0.0000\",\"1\",\"0\",\"0\",\"0.00000000\",\"1\",\"0\",\"0\",\"0.0000\",\"0\",\"0\",\"0\",NULL,\"1\",\"0\",\"0\",,NULL,NULL,\"0\",\"0\",,\"0\",\"3\",\"1\",\"3\",\"0\",\"1\"']\n",
      "['\"2015-04-01 07:11:01\",\"51\",\"94\",\"4\",\"0\",\"Change\",\"T\",\"CA\",,\"0\",\"0\",\"0\",\"0.0000\",\"0.0000\",\"3.5300\",\"0.0000\",NULL,\"0\",\"0\",\"0\",NULL,\"0.0000\",\"0.0000\",\"0\",\"0\",\"8\",NULL,\"0\",\"0\",\"0\",\"0.0000\",\"0\",\"0\",\"0\",NULL,\"0\",\"0\",\"0\",,NULL,NULL,\"0\",NULL,,\"0\",\"3\",\"1\",\"3\",\"0\",\"6\"']\n"
     ]
    },
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7a811a493ac2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mzip_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip_files\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wedge/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmy_zip_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mfiles_inside\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_zip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1266\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1333\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "zip_files = os.listdir(\"wedge/\")\n",
    "\n",
    "for zip_file in zip_files :\n",
    "    \n",
    "    with ZipFile(\"wedge/\" + zip_file, 'r') as my_zip_file:\n",
    "    \n",
    "        files_inside = my_zip_file.namelist()\n",
    "        for zipped_file in files_inside :\n",
    "            print(zipped_file)\n",
    "            \n",
    "            with my_zip_file.open(zipped_file,'r') as input_file:\n",
    "                for idx,line in enumerate(input_file):\n",
    "                    print(line.decode(\"utf-8\").strip().split(\"/t\"))\n",
    "                    if idx == 2:\n",
    "                        break\n",
    "                        \n",
    "        #print(f\"{zip_file} has this inside it {files_insdie}\")\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for delimiters\n",
    "\n",
    "Now that we can get inside these files, let's test for delimiters. First do some Googling and see if you can come up with some good approaches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Some dead space to make it easier to not peek ahead. Practice the searching!\n",
    "\n",
    "---\n",
    "\n",
    "For real!\n",
    "\n",
    "---\n",
    "\n",
    "Okay, let's get on with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `csv` module has a super-useful function called `sniffer`. It'll just let you test for delimiters. Let's see it in action. (Also, we're going to store the delimiters in a dictionary keyed to file name so that we can use them later.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like transArchive_201310_201312_small.csv has delimiter , .\n",
      "It looks like transArchive_201207_201209_small.csv has delimiter , .\n",
      "It looks like transArchive_201204_201206_inactive_small.csv has delimiter ; .\n",
      "It looks like transArchive_201304_201306_inactive_small.csv has delimiter ; .\n",
      "It looks like transArchive_201007_201009_small.csv has delimiter , .\n",
      "It looks like transArchive_201105_small.csv has delimiter , .\n",
      "It looks like transArchive_201110_201112_small.csv has delimiter , .\n",
      "It looks like transArchive_201304_201306_small.csv has delimiter , .\n",
      "It looks like transArchive_201404_201406_inactive_small.csv has delimiter ; .\n",
      "It looks like transArchive_201504_201506_small.csv has delimiter , .\n"
     ]
    },
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-52da31e66427>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis_zf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip_files\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wedge/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mthis_zf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzf\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mzipped_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1266\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1333\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "delimiters = dict() \n",
    "\n",
    "# Start by reading in all the files again.\n",
    "\n",
    "for this_zf in zip_files :\n",
    "    with ZipFile(\"wedge/\" + this_zf,'r') as zf :\n",
    "        zipped_files = zf.namelist()\n",
    "\n",
    "        for file_name in zipped_files :\n",
    "            input_file = zf.open(file_name,'r')\n",
    "            input_file = io.TextIOWrapper(input_file,encoding=\"utf-8\")\n",
    "            \n",
    "            dialect = csv.Sniffer().sniff(sample=input_file.readline(),\n",
    "                                      delimiters=[\",\",\";\",\"\\t\"])\n",
    "            \n",
    "            delimiters[file_name] = dialect.delimiter\n",
    "            \n",
    "            print(\" \".join([\"It looks like\",\n",
    "                           file_name,\n",
    "                           \"has delimiter\",\n",
    "                           dialect.delimiter,\n",
    "                           \".\"]))\n",
    "\n",
    "            input_file.close() # tidy up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read through this and try to interpret what's going on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Headers\n",
    "\n",
    "Now that we can find the delimiters, let's check for the presence of headers. First, let's \n",
    "just split the first line based on the delimiter and print that out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for this_zf in zip_files :\n",
    "    with ZipFile(\"data/\" + this_zf,'r') as zf :\n",
    "        zipped_files = zf.namelist()\n",
    "\n",
    "        for file_name in zipped_files :\n",
    "            input_file = zf.open(file_name,'r')\n",
    "            input_file = io.TextIOWrapper(input_file,encoding=\"utf-8\")\n",
    "            \n",
    "            this_delimiter = delimiters[file_name]\n",
    "            \n",
    "            for line in input_file :\n",
    "                print(line.strip().split(this_delimiter))\n",
    "                break\n",
    "\n",
    "            input_file.close() # tidy up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now rewrite the above cell so that you test for the presence of a header row and write out the True or False value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Mix of Quotes and Not\n",
    "\n",
    "There are some simple ways we can probably deal with quotes for the Wedge. If we get here, we'll discuss. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
